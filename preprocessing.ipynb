{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import scipy\n",
    "from dython.nominal import associations\n",
    "\n",
    "# Ignore future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_MAPPING_FN = \"./data/IDS_mapping.csv\"\n",
    "DIABETIC_FN = \"./data/diabetic_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "mapping = pd.read_csv(IDS_MAPPING_FN, header=None)\n",
    "df = pd.read_csv(DIABETIC_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIC_COLUMNS = df.columns[24:46].tolist()\n",
    "MEDIC_COLUMNS_TAKE = [\"take_\" + med for med in MEDIC_COLUMNS]\n",
    "PREVIOUS_HOSPITAL_ENCOUNTERS = [\"number_outpatient\", \"number_inpatient\", \"number_emergency\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of code-value mappings of `admission_type_id`, `discharge_disposition_id`, and `admission_source_id` using the mapping provided in the data-folder, and map integer values to string values for readability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_type_dict = {}\n",
    "discharge_disposition_dict = {}\n",
    "admission_source_dict = {}\n",
    "\n",
    "list1 = []\n",
    "for i, j in zip(mapping[0].values, mapping[1].values):\n",
    "  if len(str(i))>3:\n",
    "    feature_name = i\n",
    "  elif len(str(i))!=3:\n",
    "    if feature_name == 'admission_type_id':\n",
    "      admission_type_dict[int(i)] = j\n",
    "    elif feature_name == 'discharge_disposition_id':\n",
    "      discharge_disposition_dict[int(i)] = j\n",
    "    elif feature_name == 'admission_source_id':\n",
    "      admission_source_dict[int(i)] = j\n",
    "\n",
    "\n",
    "df['admission_type'] = df['admission_type_id'].apply(lambda x: admission_type_dict[x])\n",
    "df['discharge_disposition'] = df['discharge_disposition_id'].apply(lambda x: discharge_disposition_dict[x])\n",
    "df['admission_source'] = df['admission_source_id'].apply(lambda x: admission_source_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique encounters: 101766\n",
      "Number of columns: 53\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique encounters: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some patients have many encounters (up to 40).\n",
    "\n",
    "We only keep the first observation for each unique patient to treat them as i.i.d random variables.\n",
    "\n",
    "We filter to only keep observations with `admission_type` $\\in$ [Emergency, Urgent, Elective]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique encounters after only keeping first encounter for each patient and filtering by admission_type : 60571\n"
     ]
    }
   ],
   "source": [
    "df = df.groupby(\"patient_nbr\").first(skipna=False).reset_index()\n",
    "df = df[df['admission_type'].isin(['Emergency', 'Urgent', 'Elective'])]\n",
    "df = df[df['race'].isin(['Caucasian', 'AfricanAmerican', 'Hispanic', 'Asian'])]\n",
    "print(f\"Number of unique encounters after only keeping first encounter for each patient and filtering by admission_type : {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering: Diabetic Information\n",
    "\n",
    "To select features as predictor variables we are only interested in certain information about the patients, but not the exact values. Thus we aggregate the information of sets of columns into new columns:\n",
    "\n",
    "\n",
    "* Blood Glucose Tests\n",
    "\n",
    "    * `max_glu_serum_flag`: Whether a max glucose serum test was done at the hospital : `max_glu_serum`\n",
    "\n",
    "\n",
    "    * `A1C_flag`: Whether an AC1 test was performed to monitor blood glucose levels : `AC1result`\n",
    "\n",
    "    \n",
    "* Diabetic Medication Information: \n",
    "\n",
    "    * `change_dosage`: Whether there was any change (\"Up\" or \"Down\") in the diabetic prescription dosages as a result of the hospital visit.\n",
    "        * *The column `change` indicates if there was a change in diabetic medications (either dosage or generic name). So if `change` is marked as changed but `change_dosage` is none, then there must have been a change in the generic name, i.e. the chemical name of a medicine.*\n",
    "\n",
    "\n",
    "    * `change_medicine`: Whether there was prescribed any new diabetic medication i.e. a change in the medicament as a result of the hospital visit.\n",
    "\n",
    "\n",
    "    * `num_diabetic_prescriptions`: How many diabetic prescriptions the patient ongoingly had at the time of hospital visit - a count of entries that are $\\in \\{\\text{\"Steady\"}, \\text{\"Up\"}, \\text{\"Down\"}\\}$ in `MEDIC_COLUMNS`\n",
    "\n",
    "    * `take_<medicine_name>`: Whether the patient takes the <medicine_name> \n",
    "\n",
    "\n",
    "* Admitted in the hospital within the previous year\n",
    "\n",
    "    * `prev_year_hospital`: Whether the patient had any admissions in the hospital during the past year. \n",
    "\n",
    "* Health Insurance / Coverage\n",
    "\n",
    "    * `blue_cross`: Patient has private insurance\n",
    "    * `medicaid`: Patient has medicaid\n",
    "    * `medicare`: Patient has medicare\n",
    "    * `self_payed`: Patient payed up front\n",
    "  \n",
    "* `discharge_disposition_id`: is aggregated into `home`, `transfer`, `unknown`, and `other`\n",
    "\n",
    "* `Age` is aggregated into `[0-30)`, `[30-60)`, and `[60-100)`\n",
    "\n",
    "* Readmitted\n",
    "    * `readmitted_flag`: Whether the patient was readmitted or not based on the columns `readmitted`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Blood glucose Tests ####\n",
    "df['max_glu_serum_flag'] = df['max_glu_serum'].notnull().astype(int) # Max Glucose Serum test flag\n",
    "df['A1C_flag'] = df['A1Cresult'].notnull().astype(int) # AC1 test flag\n",
    "\n",
    "#### Diabetic Medication Information ####\n",
    "# Change in dosage if any of the diabetics prescriptions has entries \"Up\" or \"Down\"\n",
    "df['change_dosage'] = df[MEDIC_COLUMNS].isin(['Up', 'Down']).any(axis=1).astype(int)\n",
    "# Check if each entry is in the set ['Up', 'Down', 'Steady'] and sum all True entries for each row\n",
    "df['num_diabetic_prescriptions'] = df[MEDIC_COLUMNS].apply(lambda col: np.isin(col, ['Up', 'Down', 'Steady'])).sum(axis=1).astype(int)\n",
    "# Change in medicine is assumed to be the case when original change column = 1 but change in dosage = 0\n",
    "df['change_medicine'] = np.where((df['change'] == 'Ch') & (df['change_dosage'] == 0), 1, 0)\n",
    "\n",
    "# Whether the patient takes any of the medications\n",
    "for med in MEDIC_COLUMNS:\n",
    "    if len(np.unique(df[med])) == 1:\n",
    "        MEDIC_COLUMNS_TAKE.remove(\"take_\" + med) # some medications were taken by no patients\n",
    "        continue\n",
    "    name = \"take_\" + med\n",
    "    df[name] = df[med].isin([\"Down\", \"Steady\", \"Up\"])\n",
    "\n",
    "\n",
    "#### Hospital Encounters during preceding year ####\n",
    "df['prev_year_hospital'] = (df[PREVIOUS_HOSPITAL_ENCOUNTERS] > 0).any(axis=1).astype(int)\n",
    "\n",
    "#### Insurance Billing ####\n",
    "df['blue_cross'] = np.where(df[\"payer_code\"]==\"BC\", 1, 0)\n",
    "df['medicare'] = np.where(df[\"payer_code\"]==\"MC\", 1, 0)\n",
    "df['medicaid'] = np.where(df[\"payer_code\"]==\"MD\", 1, 0)\n",
    "df['self_pay'] = np.where(df[\"payer_code\"]==\"SP\", 1, 0)\n",
    "\n",
    "#### Discharge disposition id aggregated ####\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace([1, 6, 8, 13], \"home\")\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace([2, 3, 4, 5, 9, 10, 14, 15, 16, 17, 22, 23, 24, 27, 28, 29], \"transfer\")\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace([18, 25, 26], \"unknown\")\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace([7, 11, 12, 19, 20, 21], \"other\")\n",
    "\n",
    "#### Readmitted ####\n",
    "# y_i\n",
    "df['readmitted_flag'] = np.where(df['readmitted']=='NO', 0, 1) # Readmitted flag\n",
    "\n",
    "#### Age aggregaed ####\n",
    "df['age'] = df['age'].replace(['[0-10)', '[10-20)','[20-30)'], '[0-30)')\n",
    "df['age'] = df['age'].replace(['[30-40)', '[40-50)','[50-60)'], '[30-60)')\n",
    "df['age'] = df['age'].replace(['[60-70)', '[70-80)','[80-90)', '[90-100)'], '[60-100)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_NUM = [\"time_in_hospital\", \"num_lab_procedures\", \"num_procedures\", 'num_diabetic_prescriptions', \n",
    "                \"num_medications\", 'prev_year_hospital', \"number_diagnoses\"]\n",
    "\n",
    "FEATURES_BIN = ['max_glu_serum_flag', 'A1C_flag', 'change_dosage', 'change_medicine', \"blue_cross\", \"medicaid\", \"medicare\",\"self_pay\"]\n",
    "\n",
    "FEATURES_CAT = ['discharge_disposition_id', \"admission_type_id\"]\n",
    "\n",
    "FEATURES = FEATURES_NUM + FEATURES_BIN + FEATURES_CAT + MEDIC_COLUMNS_TAKE\n",
    "\n",
    "PROTECTED_FEATURES = ['age','race', 'gender']\n",
    "PATIENTS = [\"patient_nbr\"]  \n",
    "TARGET = [\"readmitted_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[PATIENTS + FEATURES + PROTECTED_FEATURES + TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode categorical features and protected features\n",
    "df_one_hot = pd.get_dummies(df, prefix=None, prefix_sep='_', dummy_na=False, columns=FEATURES_CAT, drop_first=False)\n",
    "df_one_hot = df_one_hot.drop([\"discharge_disposition_id_unknown\"], axis = 1)\n",
    "FEATURES_ONE_HOT = df_one_hot.drop(PATIENTS+PROTECTED_FEATURES+TARGET, axis=1).columns.tolist()\n",
    "\n",
    "df_one_hot = pd.get_dummies(df_one_hot, prefix=None, prefix_sep='_', dummy_na=False, columns=PROTECTED_FEATURES, drop_first=False)\n",
    "PROTECTED_FEATURES_ONE_HOT = df_one_hot.drop(PATIENTS+FEATURES_ONE_HOT+TARGET, axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major = df_one_hot[df_one_hot['readmitted_flag'] == 0]\n",
    "df_minor = df_one_hot[df_one_hot['readmitted_flag'] == 1]\n",
    "\n",
    "df_downsamples = resample(df_major, replace=False, n_samples=len(df_minor), random_state=42)  \n",
    "\n",
    "df_one_hot = pd.concat([df_downsamples, df_minor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_one_hot[FEATURES_ONE_HOT]\n",
    "y = df_one_hot[TARGET].to_numpy().reshape(-1)\n",
    "protected_features = df_one_hot[PROTECTED_FEATURES_ONE_HOT]\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(X, y, protected_features, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[FEATURES_NUM])\n",
    "X_train[FEATURES_NUM] = scaler.transform(X_train[FEATURES_NUM])\n",
    "X_test[FEATURES_NUM] = scaler.transform(X_test[FEATURES_NUM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Grid search and Cross Validation we found an inverse regularisation strength of $0.1$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_regression(features_train, targets_train, features_test):\n",
    "    logistic_model = LogisticRegression(max_iter=5000, penalty='l2', C=0.1, tol=1e-4, solver = \"saga\")\n",
    "    logistic_model.fit(features_train, targets_train)\n",
    "    y_pred = logistic_model.predict(features_test)\n",
    "    y_proba = logistic_model.predict_proba(features_test)\n",
    "    coefs = logistic_model.coef_\n",
    "    return y_pred, y_proba, coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_overall(y_test_, y_pred_):\n",
    "    accuracy = accuracy_score(y_test_, y_pred_)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_, y_pred_)\n",
    "    \n",
    "    return accuracy, tpr[1], fpr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_per_group(group_test_: pd.DataFrame(), y_test_: np.array(), y_pred_: np.array(), protected_group: str, protected_feature_names=PROTECTED_FEATURES_ONE_HOT):\n",
    "    '''\n",
    "    Calculates accuracy, true positive rate, (tpr), and false positive rate (fpr) for the specified protected group. \n",
    "    '''\n",
    "    group_names, accuracies, tprs, fprs = [], [], [], []\n",
    "    protected_feature_names = [group for group in protected_feature_names if protected_group in group]\n",
    "    df_ = pd.concat([group_test_, pd.DataFrame({'y_test': y_test_, 'y_pred': y_pred_}, index=group_test_.index)], axis=1)\n",
    "    \n",
    "    for group_col in protected_feature_names:\n",
    "        group_df = df_[df_[group_col]==True]\n",
    "        y_true = group_df['y_test']\n",
    "        y_pred = group_df['y_pred']\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        \n",
    "        group_names.append(group_col)\n",
    "        accuracies.append(accuracy)\n",
    "        tprs.append(tpr[1])\n",
    "        fprs.append(fpr[1])\n",
    "        \n",
    "    return group_names, accuracies, tprs, fprs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorrelate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the function for decorrelating features using the method from the paper \"A Geometric Solution to Fair Representations\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_remover(features, protected_features, lambda_):\n",
    "    '''\n",
    "    Decorrelate non-protected features with protected features.\n",
    "    Lambda_ (fairness level) is in the interval [0,1], where 0; high fairness and 1; low fairness. \n",
    "    '''\n",
    "    assert features.shape[0]==protected_features.shape[0]\n",
    "    \n",
    "    features_cols = features.columns\n",
    "    \n",
    "    #convert features to numeric matrices so we can do linalg operations\n",
    "    features = features.astype(int).values\n",
    "    protected_features = protected_features.astype(int).values\n",
    "    \n",
    "    # Find orthonormal basis of protected features\n",
    "    orthobasis = scipy.linalg.orth(protected_features)\n",
    "    \n",
    "    # calculate projection of non-protected features onto orthonormal basis)\n",
    "    features_decorrelated = features - orthobasis @ (orthobasis.T @ features)\n",
    "    \n",
    "    # Controlling the level of fairness. Subtract the projection from the original nonprotected features and scaling with fairness_level.\n",
    "    features_decorrelated = features_decorrelated + lambda_ * (features - features_decorrelated)\n",
    "    \n",
    "    #convert to dataframe using the extracted column names\n",
    "    features_decorrelated = pd.DataFrame(features_decorrelated, columns=features_cols)\n",
    "    \n",
    "    return features_decorrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracies, tprs, fprs = [], [], []\n",
    "gender_accuracies, gender_tprs, gender_fprs = [], [], []\n",
    "race_accuracies, race_tprs, race_fprs = [], [], []\n",
    "age_accuracies, age_tprs, age_fprs = [], [], []\n",
    "\n",
    "num_lambda = 31\n",
    "#for lambda_ in np.logspace(-(num_lambda-1), 0, num_lambda):\n",
    "for lambda_ in np.linspace(0,1,num_lambda):\n",
    "    X_train_decorrelated = correlation_remover(X_train, group_train, lambda_)\n",
    "    X_test_decorrelated = correlation_remover(X_test, group_test, lambda_)\n",
    "    \n",
    "    predictions, _, _ = fit_logistic_regression(X_train_decorrelated, y_train, X_test_decorrelated)\n",
    "    \n",
    "    accuracy, tpr, fpr = get_metrics_overall(y_test, predictions)\n",
    "    gender_name, gender_accuracy, gender_tpr, gender_fpr = get_metrics_per_group(group_test, y_test, predictions, 'gender')\n",
    "    race_name, race_accuracy, race_tpr, race_fpr = get_metrics_per_group(group_test, y_test, predictions, 'race')\n",
    "    age_name, age_accuracy, age_tpr, age_fpr = get_metrics_per_group(group_test, y_test, predictions, 'age')\n",
    "        \n",
    "    #Append to all lists\n",
    "    overall_accuracies.append(accuracy)\n",
    "    tprs.append(tpr)\n",
    "    fprs.append(fpr)\n",
    "    \n",
    "    gender_accuracies.append(gender_accuracy)\n",
    "    gender_tprs.append(gender_tpr)\n",
    "    gender_fprs.append(gender_fpr)\n",
    "    \n",
    "    race_accuracies.append(race_accuracy)\n",
    "    race_tprs.append(race_tpr)\n",
    "    race_fprs.append(race_fpr)\n",
    "    \n",
    "    age_accuracies.append(age_accuracy)\n",
    "    age_tprs.append(age_tpr)\n",
    "    age_fprs.append(age_fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot_protected = pd.get_dummies(df[PROTECTED_FEATURES], prefix=None, prefix_sep='_', dummy_na=False, columns=PROTECTED_FEATURES, drop_first=False) \n",
    "corr_matrix = associations(pd.concat([df[FEATURES], df_one_hot_protected], axis=1), figsize=(20, 20), plot=False, num_num_assoc='pearson')\n",
    "corr_matrix = corr_matrix['corr'][df_one_hot_protected.columns.tolist()].reset_index()\n",
    "corr_matrix = corr_matrix.drop([i for i in range(len(FEATURES)-1,corr_matrix.shape[0])])\n",
    "corr_matrix = corr_matrix.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 10))\n",
    "# sns.heatmap(corr_matrix, annot=False, cmap='vlag', fmt=\".1f\", cbar=True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
