{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_MAPPING_FN = \"./data/IDS_mapping.csv\"\n",
    "DIABETIC_FN = \"./data/diabetic_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "mapping = pd.read_csv(IDS_MAPPING_FN, header=None)\n",
    "df = pd.read_csv(DIABETIC_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIC_COLUMNS = df.columns[23:46].tolist()\n",
    "PREVIOUS_HOSPITAL_ENCOUNTERS = [\"number_outpatient\", \"number_inpatient\", \"number_emergency\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of code-value mappings of `admission_type_id`, `discharge_disposition_id`, and `admission_source_id` using the mapping provided in the data-folder, and map integer values to string values for readability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_type_dict = {}\n",
    "discharge_disposition_dict = {}\n",
    "admission_source_dict = {}\n",
    "\n",
    "list1 = []\n",
    "for i, j in zip(mapping[0].values, mapping[1].values):\n",
    "  if len(str(i))>3:\n",
    "    feature_name = i\n",
    "  elif len(str(i))!=3:\n",
    "    if feature_name == 'admission_type_id':\n",
    "      admission_type_dict[int(i)] = j\n",
    "    elif feature_name == 'discharge_disposition_id':\n",
    "      discharge_disposition_dict[int(i)] = j\n",
    "    elif feature_name == 'admission_source_id':\n",
    "      admission_source_dict[int(i)] = j\n",
    "\n",
    "\n",
    "df['admission_type'] = df['admission_type_id'].map(admission_type_dict).astype(\"O\")\n",
    "df['discharge_disposition'] = df['discharge_disposition_id'].map(discharge_disposition_dict).astype(\"O\")\n",
    "df['admission_source'] = df['admission_source_id'].map(admission_source_dict).astype(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique encounters: 101766\n",
      "Number of columns: 53\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique encounters: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some patients have many encounters (up to 40).\n",
    "\n",
    "We only keep the first observation for each unique patient to treat them as i.i.d random variables.\n",
    "\n",
    "We filter to only keep observations with `admission_type` $\\in$ [Emergency, Urgent, Elective]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique encounters after only keeping first encounter for each patient and filtering by admission_type : 63757\n"
     ]
    }
   ],
   "source": [
    "df = df.groupby(\"patient_nbr\").agg('first').reset_index()\n",
    "df = df[df['admission_type'].isin(['Emergency', 'Urgent', 'Elective'])]\n",
    "print(f\"Number of unique encounters after only keeping first encounter for each patient and filtering by admission_type : {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering: Diabetic Information\n",
    "\n",
    "To select features as predictor variables we are only interested in certain information about the patients, but not the exact values. Thus we aggregate the information of sets of columns into new columns:\n",
    "\n",
    "\n",
    "* Blood Glucose Tests\n",
    "\n",
    "    * `max_glu_serum_flag`: Whether a max glucose serum test was done at the hospital : `max_glu_serum`\n",
    "\n",
    "\n",
    "    * `A1C_flag`: Whether an AC1 test was performed to monitor blood glucose levels : `AC1result`\n",
    "\n",
    "    \n",
    "* Diabetic Medication Information: \n",
    "\n",
    "    * `change_dosage`: Whether there was any change (\"Up\" or \"Down\") in the diabetic prescription dosages as a result of the hospital visit.\n",
    "        * *The column `change` indicates if there was a change in diabetic medications (either dosage or generic name). So if `change` is marked as changed but `change_dosage` is none, then there must have been a change in the generic name, i.e. the chemical name of a medicine.*\n",
    "\n",
    "\n",
    "    * `change_medicine`: Whether there was prescribed any new diabetic medication i.e. a change in the medicament as a result of the hospital visit.\n",
    "\n",
    "\n",
    "    * `num_diabetic_prescriptions`: How many diabetic prescriptions the patient ongoingly had at the time of hospital visit - a count of entries that are $\\in \\{\\text{\"Steady\"}, \\text{\"Up\"}, \\text{\"Down\"}\\}$ in `MEDIC_COLUMNS`\n",
    "\n",
    "\n",
    "* Admitted in the hospital within the previous year\n",
    "\n",
    "    * `prev_year_hospital`: Whether the patient had any admissions in the hospital during the past year. \n",
    "\n",
    "* Health Insurance / Coverage\n",
    "\n",
    "    * `blue_cross`: Patient has private insurance\n",
    "    * `medicaid`: Patient has medicaid\n",
    "    * `medicare`: Patient has medicare\n",
    "    * `self_payed`: Patient payed up front\n",
    "\n",
    "* Readmitted\n",
    "    * `readmitted_flag`: Whether the patient was readmitted or not within 30 days based on the columns `readmitted`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Blood glucose Tests ####\n",
    "df['max_glu_serum_flag'] = df['max_glu_serum'].notnull().astype(int) # Max Glucose Serum test flag\n",
    "df['A1C_flag'] = df['A1Cresult'].notnull().astype(int) # AC1 test flag\n",
    "\n",
    "#### Diabetic Medication Information ####\n",
    "# Change in dosage if any of the diabetics prescriptions has entries \"Up\" or \"Down\"\n",
    "df['change_dosage'] = df[MEDIC_COLUMNS].isin(['Up', 'Down']).any(axis=1).astype(int)\n",
    "# Check if each entry is in the set ['Up', 'Down', 'Steady'] and sum all True entries for each row\n",
    "df['num_diabetic_prescriptions'] = df[MEDIC_COLUMNS].apply(lambda col: np.isin(col, ['Up', 'Down', 'Steady'])).sum(axis=1).astype(int)\n",
    "# Change in medicine is assumed to be the case when original change column = 1 but change in dosage = 0\n",
    "df['change_medicine'] = np.where((df['change'] == 'Ch') & (df['change_dosage'] == 0), 1, 0)\n",
    "\n",
    "#### Hospital Encounters during preceding year ####\n",
    "df['prev_year_hospital'] = (df[PREVIOUS_HOSPITAL_ENCOUNTERS] > 0).any(axis=1).astype(int)\n",
    "\n",
    "#### Insurance Billing ####\n",
    "df['blue_cross'] = np.where(df[\"payer_code\"]==\"BC\", 1, 0)\n",
    "df['medicare'] = np.where(df[\"payer_code\"]==\"MC\", 1, 0)\n",
    "df['medicaid'] = np.where(df[\"payer_code\"]==\"MD\", 1, 0)\n",
    "df['self_pay'] = np.where(df[\"payer_code\"]==\"SP\", 1, 0)\n",
    "\n",
    "#### Readmitted ####\n",
    "# y_i\n",
    "# df['readmitted_flag'] = np.where(df['readmitted']=='<30', 1, 0) # Readmitted flag\n",
    "df['readmitted_flag'] = np.where(df['readmitted']=='NO', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"time_in_hospital\", \"admission_type_id\", \"num_lab_procedures\", \"num_procedures\", \n",
    "            \"num_medications\", 'prev_year_hospital', \"number_diagnoses\", 'max_glu_serum_flag', \n",
    "            'A1C_flag', 'change_dosage', 'change_medicine', 'num_diabetic_prescriptions', \"blue_cross\", \"medicaid\", \"medicare\",\"self_pay\"]\n",
    "PROTECTED_FEATURES = ['age', 'race', 'gender']\n",
    "PATIENTS = [\"patient_nbr\"]  \n",
    "TARGET = [\"readmitted_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_50_60 = df[df[\"age\"]== \"[50-60)\"]\n",
    "# df_60_70 = df[df[\"age\"]== \"[60-70)\"]\n",
    "# df_70_80 = df[df[\"age\"]== \"[70-80)\"]\n",
    "# df_80_90 = df[df[\"age\"]== \"[80-90)\"]\n",
    "# df = pd.concat([df_80_90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63757, 21) 0    38626\n",
      "1    25131\n",
      "Name: readmitted_flag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[PATIENTS + FEATURES + PROTECTED_FEATURES + TARGET]\n",
    "print(df.shape, df[\"readmitted_flag\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmitted_flag\n",
      "0                  25131\n",
      "1                  25131\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['readmitted_flag'] == 0]\n",
    "df_minority = df[df['readmitted_flag'] == 1]\n",
    "\n",
    "# Downsample the majority class to have the same number of observations as the minority class\n",
    "df_majority_downsampled = resample(df_majority,\n",
    "                                   replace=False,  # Sample without replacement\n",
    "                                   n_samples=len(df_minority),  # Number of samples to match minority class\n",
    "                                   random_state=42)  # For reproducibility\n",
    "\n",
    "# Combine the downsampled majority class with the minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Shuffle the DataFrame to randomize the order of samples\n",
    "df_downsampled = df_downsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the number of samples for each class after downsampling\n",
    "print(df_downsampled[TARGET].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# X,y = df[FEATURES].to_numpy(), df[TARGET].to_numpy()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X,y = df_downsampled[FEATURES].to_numpy(), df_downsampled[TARGET].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import L1, L2\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(16,))\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "outputs = keras.layers.Dense(1, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "322/322 [==============================] - 1s 941us/step - loss: 1.5179 - accuracy: 0.4989 - val_loss: 1.3447 - val_accuracy: 0.5030\n",
      "Epoch 2/10\n",
      "322/322 [==============================] - 0s 957us/step - loss: 1.1883 - accuracy: 0.4989 - val_loss: 1.0761 - val_accuracy: 0.5030\n",
      "Epoch 3/10\n",
      "322/322 [==============================] - 0s 921us/step - loss: 0.9924 - accuracy: 0.4989 - val_loss: 0.9333 - val_accuracy: 0.5030\n",
      "Epoch 4/10\n",
      "322/322 [==============================] - 0s 759us/step - loss: 0.8955 - accuracy: 0.4989 - val_loss: 0.8638 - val_accuracy: 0.5030\n",
      "Epoch 5/10\n",
      "322/322 [==============================] - 0s 694us/step - loss: 0.8460 - accuracy: 0.4989 - val_loss: 0.8239 - val_accuracy: 0.5030\n",
      "Epoch 6/10\n",
      "322/322 [==============================] - 0s 691us/step - loss: 0.8134 - accuracy: 0.4989 - val_loss: 0.7952 - val_accuracy: 0.5030\n",
      "Epoch 7/10\n",
      "322/322 [==============================] - 0s 709us/step - loss: 0.7884 - accuracy: 0.4989 - val_loss: 0.7735 - val_accuracy: 0.5030\n",
      "Epoch 8/10\n",
      "322/322 [==============================] - 0s 693us/step - loss: 0.7699 - accuracy: 0.4989 - val_loss: 0.7583 - val_accuracy: 0.5030\n",
      "Epoch 9/10\n",
      "322/322 [==============================] - 0s 671us/step - loss: 0.7567 - accuracy: 0.4989 - val_loss: 0.7474 - val_accuracy: 0.5030\n",
      "Epoch 10/10\n",
      "322/322 [==============================] - 0s 718us/step - loss: 0.7472 - accuracy: 0.4989 - val_loss: 0.7395 - val_accuracy: 0.5030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2f3c847c0>"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=10, batch_size=100, validation_split=0.2,callbacks=[keras.callbacks.EarlyStopping(patience=2)],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 337us/step\n",
      "315/315 [==============================] - 0s 311us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)\n",
    "\n",
    "np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 410us/step - loss: 0.7472 - accuracy: 0.5012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7472116947174072, 0.5012434124946594]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LightGBM Datasets for training and validation \n",
    "train_data = lgb.Dataset(X_train, label=y_train) \n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data) \n",
    "  \n",
    "# Define hyperparameters and objective for LightGBM \n",
    "params = { \n",
    "    'objective': 'binary', \n",
    "    'metric': 'accuracy', \n",
    "    'boosting_type': 'gbdt', \n",
    "    'num_leaves': 31, \n",
    "    'learning_rate': 0.05, \n",
    "    'feature_fraction': 0.9, \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20092, number of negative: 20117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 241\n",
      "[LightGBM] [Info] Number of data points in the train set: 40209, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499689 -> initscore=-0.001244\n",
      "[LightGBM] [Info] Start training from score -0.001244\n"
     ]
    }
   ],
   "source": [
    "num_round = 100\n",
    "  \n",
    "# Train a LightGBM model using defined parameters, training data, and specified number of rounds \n",
    "model = lgb.train(params, train_data, \n",
    "                  num_round, valid_sets=[test_data]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb = np.argmax(np.array(model.predict(X_test)).reshape(-1,1),axis=1)\n",
    "# print(np.array(y_pred_lgb).reshape(-1,1).shape)\n",
    "# print(y_test.shape)\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49875659007261514"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
